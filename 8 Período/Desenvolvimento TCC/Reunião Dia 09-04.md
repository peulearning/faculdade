1. Informa√ß√£o generalista ( dimens√£o de 224x224 ) [X]
2. Porque definiram padr√£o 224x224  ( Pesquisar na arquitetura Alexnet ) [X]
3. Diferen√ßas Similaridades dos termos : Teste e Valida√ß√£o em IA [X] 
4. Diferen√ßas de Rede Neural x Rede Convolucional  [X ] 
5. Qual as vantagens da utiliza√ß√£o da rede neural convolucional ? Porque os artigos defendem .Qual a aplica√ß√£o dela para vis√£o computacional . [X] 
	1. O que e mais imporante no contexto de imagens, sa√∫de, feridas ( TRABALHO DE CLASSIFCA√á√ÉO ) al√©m da accuracy oque e mais interessante de verificar, Precision ou Recall. [ X] 


###  üìå **Informa√ß√£o generalista (dimens√£o 224x224)**

A dimens√£o **224x224** √© uma conven√ß√£o comum no **pr√©-processamento de imagens para redes neurais convolucionais (CNNs)**. Isso significa redimensionar todas as imagens de entrada para esse tamanho antes de aliment√°-las ao modelo.

- Essa dimens√£o √© **pequena o suficiente** para garantir **efici√™ncia computacional**, mas **grande o suficiente** para reter **informa√ß√£o visual relevante**.
    
- Muitos modelos pr√©-treinados como **VGG16**, **ResNet** e **AlexNet** utilizam essa dimens√£o como padr√£o de entrada.
    Fonte : https://medium.com/swlh/alexnet-the-cnn-that-changed-computer-vision-9a1f4a50142d?utm_source=chatgpt.com

---

### üìå **Por que definiram o padr√£o 224x224? (AlexNet)**

O padr√£o de 224x224 surgiu com **AlexNet**, uma das primeiras CNNs a se destacar em desafios como o **ImageNet** (2012).

- AlexNet usou 224x224 porque era um **compromisso entre qualidade da imagem e capacidade computacional** dispon√≠vel na √©poca (usavam GPUs com 2GB de RAM).
    
- **Imagens muito maiores** seriam mais pesadas para o processamento, e **imagens muito pequenas** perderiam detalhes importantes.
    
- Essa dimens√£o tamb√©m funcionava bem para **convolu√ß√µes com filtros 3x3 e 5x5**, comuns naquela arquitetura.
    Fonte : https://discuss.pytorch.org/t/alexnet-input-size-224-or-227/41272?utm_source=chatgpt.com

---

### üìå **Diferen√ßas e Similaridades: Teste vs Valida√ß√£o em IA**

|Aspecto|Valida√ß√£o|Teste|
|---|---|---|
|**Objetivo**|Avaliar o modelo durante o treinamento (para ajuste de hiperpar√¢metros)|Avaliar o desempenho final do modelo|
|**Uso**|Durante o treinamento|Ap√≥s o treinamento|
|**Conjunto de dados**|Dados separados do treino, mas ainda vis√≠veis ao modelo|Dados nunca vistos pelo modelo|
|**Import√¢ncia**|Para evitar overfitting durante o desenvolvimento|Para avaliar a generaliza√ß√£o real|

> **Similaridade**: Ambos n√£o s√£o usados para treinar o modelo e servem para **avaliar desempenho**.
> Fonte :  https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set?utm_source=chatgpt.com
---

### üìå **Diferen√ßas: Rede Neural x Rede Neural Convolucional**

| Caracter√≠stica              | Rede Neural (MLP)    | Rede Neural Convolucional (CNN)      |
| --------------------------- | -------------------- | ------------------------------------ |
| Estrutura                   | Totalmente conectada | Camadas com filtros convolucionais   |
| Processamento de Imagem     | N√£o √© eficiente      | Especializada para imagens           |
| Extra√ß√£o de Caracter√≠sticas | Manual               | Autom√°tica (usa filtros)             |
| Complexidade                | Mais simples         | Mais complexa                        |
| Espa√ßo de par√¢metros        | Muito maior          | Muito menor (usa peso compartilhado) |

> **Resumo**: A CNN √© otimizada para trabalhar com imagens, extraindo automaticamente padr√µes visuais como bordas, texturas e formas.
Fonte : https://www.baeldung.com/cs/convolutional-vs-regular-nn?utm_source=chatgpt.com


### üìå **Porque os artigos defendem .Qual a aplica√ß√£o dela para vis√£o computacional**

Fonte : https://ojs.revistacontemporanea.com/ojs/index.php/home/article/view/7190/5125

### üìå**Vantagens das Redes Convolucionais (CNNs)**

**Por que os artigos defendem o uso de CNNs?**

- **Alta acur√°cia** na classifica√ß√£o de imagens.
    
- **Aprendem sozinhas as caracter√≠sticas** (features) mais importantes da imagem.
    
- **Peso compartilhado e localidade dos filtros** reduzem a quantidade de par√¢metros e aumentam a efici√™ncia.
    
- Usadas amplamente em tarefas de **vis√£o computacional**: detec√ß√£o de objetos, segmenta√ß√£o, classifica√ß√£o, etc.
    

**Aplica√ß√£o em vis√£o computacional:**

- Diagn√≥stico por imagem (radiologia, dermatologia)
    
- Reconhecimento facial
    
- An√°lise de feridas, les√µes, tumores
    
- Classifica√ß√£o de c√©lulas ou tecidos em imagens microsc√≥picas
    

	Fonte : https://medium.com/%40tam.tamanna18/exploring-convolutional-neural-networks-architecture-steps-use-cases-and-pros-and-cons-b0d3b7d46c71

---

### üìå **No contexto de imagens m√©dicas (feridas), al√©m da Accuracy, o que √© mais interessante: Precision ou Recall?**

Depende do objetivo, mas **geralmente o mais importante √© o `Recall`**.

#### üß† Por qu√™?

- **Recall** (Sensibilidade) mede **quantos casos positivos reais foram corretamente identificados**.
    
- Em sa√∫de, **errar um caso positivo (falso negativo)** pode ser grave. Ex: n√£o detectar uma ferida infectada.
    

| M√©trica       | Interpreta√ß√£o no contexto de sa√∫de                                                 |
| ------------- | ---------------------------------------------------------------------------------- |
| **Accuracy**  | Boa no geral, mas pode ser enganosa em bases desbalanceadas                        |
| **Precision** | Evita falsos positivos (ex: marcar uma ferida como grave quando n√£o √©)             |
| **Recall**    | Evita falsos negativos (ex: deixar de detectar uma ferida grave) ‚úÖ mais importante |
| **F1-Score**  | M√©dia harm√¥nica entre Precision e Recall (boa para equil√≠brio)                     |

Fonte : https://en.wikipedia.org/wiki/Precision_and_recall

Altera√ß√µes Pontuais no C√≥digo 