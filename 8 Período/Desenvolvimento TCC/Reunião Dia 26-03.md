
Executar os Steps e Explicar [  ] 
Entender porque a dimens√£o 224x224 foi utilizada [ x ]  ( Poss√≠vel Testar em resolu√ß√£o 256x256 ou 512x512 )  
Procurar Artigos 5 √° 10 quais motiva√ß√µes de utilizar Vis√£o Computacional com Feridas. [ x ]  
### üìå **1. Padr√£o de Modelos Pr√©-Treinados**

A resolu√ß√£o **224√ó224** foi popularizada pelo modelo **AlexNet** (2012) e depois utilizada em redes como **VGG16, ResNet, MobileNet e EfficientNet**. Muitas arquiteturas modernas usam esse tamanho como entrada padr√£o, pois os pesos pr√©-treinados esperam essa dimens√£o.

**Exemplo:** Modelos como `ResNet-50` e `MobileNetV2` aceitam 224x224 como entrada padr√£o.
 
### üìå **2. Efici√™ncia Computacional e Mem√≥ria**

Redes neurais convolucionais (CNNs) operam melhor quando a imagem tem **tamanho fixo**. Se as imagens fossem maiores, exigiriam mais mem√≥ria e processamento. Se fossem muito pequenas, perderiam detalhes importantes.

- **224x224** √© um **compromisso entre qualidade e efici√™ncia**.
    
- **Menores que isso**: perda de detalhes.
    
- **Maiores que isso**: aumento do custo computacional.
    

**Exemplo pr√°tico:**  
Uma imagem de **1024x1024** tem **1.048.576 pixels**. J√° uma de **224x224** tem **50.176 pixels**, sendo **20√ó menor**, reduzindo o tempo de treinamento.

### **üìå 3. Preserva√ß√£o de Informa√ß√µes Relevantes**

Ao redimensionar para **224x224**, **mantemos detalhes essenciais** da imagem sem comprometer a qualidade para redes neurais convolucionais (CNNs).  
Se usarmos um tamanho muito pequeno, a CNN pode perder informa√ß√µes importantes, especialmente para **segmenta√ß√£o e classifica√ß√£o de les√µes cut√¢neas**.

**Exemplo:**  
Uma les√£o pequena pode desaparecer se reduzirmos para **64x64**, mas em **224x224** ainda conseguimos ver bordas e texturas.

### üìå **4. Aplica√ß√£o no Reconhecimento de Les√µes Cut√¢neas**

Em aplica√ß√µes m√©dicas, como a **segmenta√ß√£o e classifica√ß√£o de feridas**, a dimens√£o **224x224** √© suficiente para capturar caracter√≠sticas como:

- **Textura da pele**
    
- **Bordas da les√£o**
    
- **Padr√µes de colora√ß√£o**
    
- **Detalhes pequenos, mas importantes**
    

Se aumentarmos muito a resolu√ß√£o, apenas aumentamos o custo de processamento **sem melhorar significativamente a precis√£o**.

### üìå **5. Consist√™ncia entre Amostras**

Usar **224x224** para todas as imagens padroniza os dados de entrada, tornando o treinamento mais eficiente e evitando que a CNN precise lidar com tamanhos variados.

Sem um tamanho fixo, precisar√≠amos de **camadas adaptativas** ou realizar **padding**, o que poderia introduzir distor√ß√µes.


### ‚ö° **1. Redes  Convolucionais Par√¢metros T√©cnicos**

https://www.youtube.com/watch?v=lb5ocJiDLgg&t=1268s - Redes Neurais Convolucionais

Estamos Tratando de Dados Complexos ( Imagens )

* Imagem , Texto, Grafos, A√∫dio.

Dados Complexos : Alta dimensionalidade (Grande n√∫mero de Atributos e Caracter√≠sticas ) em outras palavras cada pixel e um dado.  Uma imagem de 7x7 pixels e menos que um √≠cone ou seja mesmo pequenas imagem pequenas existe uma quantidade absurda de atributos. ainda assim os dados s√£o " N√ÉO ESTRUTURADOS " pois as informa√ß√µes necess√°rias est√£o distribu√≠das em v√°rios pixels, dando o fato que precisa ser LIMPADO para conseguirmos extrair as caracter√≠sticas necess√°rias.

Problemas dos dados  Complexos : Redund√¢ncia doa dados, padr√µes distribu√≠dos em muitos atributos .  Feature Engineering  ( Limpeza de Dados, Transforma√ß√£o dos Dados, Sele√ß√£o das Caracter√≠sticas ), Reconhecimento de Padr√µes . 

Exemplo  : Conjunto de imagem de D√≠gitos  cujo objetivo e identificar dentro das imagens os subconjuntos de pixels (atributos caracter√≠sticas ) que identifique um determinado padr√£o  ent√£o o algoritmo deve encontrar as caracter√≠sticas mais fortes de uma classe para outras e ap√≥s a extra√ß√£o desse conjunto de pixels s√£o as caracter√≠sticas e ap√≥s extra√≠dos 

Aprendizagem de M√°quina Cl√°ssico ( Shallow ) era utilizado essa etapas at√© agora feito a m√£o

* Atributos Simples, Estruturados, Baixa Dimensionalidade  
*  Previamente Selecionados / Manipulados ( Engenharia de Caracter√≠sticas )
* Modelos Simples ( Rasos - Shallow ( OpenCV2  >> SVM  ( Classificador Linear Filtros  )))
* Poucos par√¢metros

Aprendizado Profundo ( Deep Learning )

* Atributos Complexos :  N√£o estruturados, Alta Dimensionalidade
* Previamente Selecionados / Manipulados ( Engenharia de Caracter√≠sticas )
*  O pr√≥prio modelo aprende como : Selecionar e extrair caracter√≠sticas , reconhece padr√µes de caracter√≠sticas
* Modelos Complexos : Milhares  / Milh√µes de Par√¢metros 
* 